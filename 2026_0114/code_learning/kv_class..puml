@startuml
title vLLM v1 Hybrid KV Cache Manager (HMA) - 核心类图

skinparam classAttributeIconSize 0
skinparam packageStyle rectangle
skinparam shadowing false
skinparam linetype ortho

package "vllm.v1.core" as core {

  class KVCacheManager <<interface>> {
    +allocate(...)
    +free(...)
    +cache_blocks(...)
    +get_blocks(...)
    ..(对 scheduler 暴露的接口层)..
  }

  class KVCacheCoordinator <<abstract>> {
    -kv_cache_config: KVCacheConfig
    -max_model_len: int
    -enable_caching: bool
    -use_eagle: bool
    -block_pool: BlockPool
    -single_type_managers: tuple[SingleTypeKVCacheManager]
    --
    +get_num_blocks_to_allocate(request_id, num_tokens, new_computed_blocks, num_encoder_tokens): int
    +save_new_computed_blocks(request_id, new_computed_blocks): void
    +allocate_new_blocks(request_id, num_tokens, num_encoder_tokens=0): tuple[list[KVCacheBlock], ...]
    +cache_blocks(request, num_computed_tokens): void
    +free(request_id): void
    +remove_skipped_blocks(request_id, num_computed_tokens): void
    +get_blocks(request_id): tuple[list[KVCacheBlock], ...]
    +find_longest_cache_hit(block_hashes, max_cache_hit_length): (hit_blocks, hit_length) <<abstract>>
  }

  class KVCacheCoordinatorNoPrefixCache {
    +find_longest_cache_hit(...): ([], 0)
    ..(禁用 prefix caching 或不支持时使用)..
  }

  class UnitaryKVCacheCoordinator {
    -kv_cache_spec: KVCacheSpec
    -block_size: int
    +find_longest_cache_hit(...): (hit_blocks, hit_length)
    ..(只有 1 个 KV group)..
  }

  class HybridKVCacheCoordinator {
    -hash_block_size: int
    -full_attention_group_ids: list[int]
    -other_group_ids: list[int]
    -full_attention_spec: FullAttentionSpec
    -other_spec: KVCacheSpec
    -full_attention_block_size: int
    -other_block_size: int
    -lcm_block_size: int
    -full_attn_first: bool
    --
    +verify_and_split_kv_cache_groups(): void
    +find_longest_cache_hit(...): (hit_blocks, hit_length)
    ..(只支持两类 group，且必须 full + X；DCP/PCP 目前限制为1)..
  }

  class BlockPool {
    -num_blocks: int
    -enable_caching: bool
    -hash_block_size: int
    -null_block: KVCacheBlock
    --
    +get_new_blocks(n): list[KVCacheBlock]
    +free_blocks(blocks): void
    +cache_full_blocks(request, blocks, num_cached_blocks, num_full_blocks, block_size, kv_cache_group_id): void
    +get_cached_block(block_hash, kv_cache_group_ids): tuple[KVCacheBlock]?
    ..(缓存 key 逻辑上等价于 (block_hash, group_id) 维度隔离)..
  }

  class SingleTypeKVCacheManager <<abstract>> {
    -block_size: int
    -kv_cache_spec: KVCacheSpec
    -block_pool: BlockPool
    -kv_cache_group_id: int
    -req_to_blocks: map[request_id -> list[KVCacheBlock]]
    -num_cached_block: map[request_id -> int]
    -_null_block: KVCacheBlock
    --
    +get_num_blocks_to_allocate(request_id, num_tokens, new_computed_blocks): int
    +save_new_computed_blocks(request_id, new_computed_blocks): void
    +allocate_new_blocks(request_id, num_tokens): list[KVCacheBlock]
    +cache_blocks(request, num_tokens): void
    +free(request_id): void
    +remove_skipped_blocks(request_id, num_computed_tokens): void
    +get_num_skipped_tokens(num_computed_tokens): int
    +get_num_common_prefix_blocks(running_request_id): int <<abstract>>
    --
    +find_longest_cache_hit(block_hashes, max_length, kv_cache_group_ids, block_pool, kv_cache_spec, use_eagle, alignment_tokens, dcp_world_size=1, pcp_world_size=1) <<abstract static>>
  }

  class FullAttentionManager {
    +find_longest_cache_hit(...): tuple[list[KVCacheBlock], ...]
    +get_num_common_prefix_blocks(...): int
    ..(从左到右找连续命中；可对齐 alignment_tokens；eagle 可能 drop last)..
  }

  class SlidingWindowManager {
    -sliding_window: int
    +find_longest_cache_hit(...): tuple[list[KVCacheBlock], ...]
    +get_num_skipped_tokens(num_computed_tokens): int
    +get_num_common_prefix_blocks(...): int
    ..(从右到左找“窗口尾部连续命中”；窗口外 blocks 会被置 NULL 并释放)..
  }

  class ChunkedLocalAttentionManager {
    -attention_chunk_size: int
    +find_longest_cache_hit(...): tuple[list[KVCacheBlock], ...]
    +get_num_skipped_tokens(...): int
    ..(局部窗口/分块局部注意力的 skipped/NULL 逻辑)..
  }

  class CrossAttentionManager {
    +get_num_blocks_to_allocate(request_id, num_encoder_tokens, []): int
    +allocate_new_blocks(request_id, num_encoder_tokens): list[KVCacheBlock]
    ..(按 encoder tokens 做静态分配)..
  }

  class Request {
    +request_id: str
    +prompt_token_ids: list[int]
    +...
  }

  class KVCacheBlock {
    +block_id: int
    +ref_cnt: int
    +is_null: bool
  }

  class KVCacheConfig {
    +num_blocks: int
    +kv_cache_groups: list[KVCacheGroupSpec]
    +kv_cache_tensors: ...
  }

  class KVCacheGroupSpec {
    +layer_names: list[str]
    +kv_cache_spec: KVCacheSpec
  }

  class KVCacheSpec <<abstract>> {
    +block_size: int
    +page_size_bytes: int
    +max_memory_usage_bytes(vllm_config): int
  }

  class FullAttentionSpec
  class SlidingWindowSpec
  class ChunkedLocalAttentionSpec
  class MambaSpec
  class CrossAttentionSpec

  KVCacheSpec <|-- FullAttentionSpec
  KVCacheSpec <|-- SlidingWindowSpec
  KVCacheSpec <|-- ChunkedLocalAttentionSpec
  KVCacheSpec <|-- MambaSpec
  KVCacheSpec <|-- CrossAttentionSpec

  SingleTypeKVCacheManager <|-- FullAttentionManager
  SingleTypeKVCacheManager <|-- SlidingWindowManager
  SingleTypeKVCacheManager <|-- ChunkedLocalAttentionManager
  SingleTypeKVCacheManager <|-- CrossAttentionManager

  KVCacheCoordinator <|-- KVCacheCoordinatorNoPrefixCache
  KVCacheCoordinator <|-- UnitaryKVCacheCoordinator
  KVCacheCoordinator <|-- HybridKVCacheCoordinator

  KVCacheCoordinator *-- BlockPool
  KVCacheCoordinator *-- "0..*" SingleTypeKVCacheManager
  KVCacheConfig o-- "1..*" KVCacheGroupSpec
  KVCacheGroupSpec o-- KVCacheSpec
  SingleTypeKVCacheManager o-- BlockPool
  SingleTypeKVCacheManager o-- KVCacheSpec
  SingleTypeKVCacheManager o-- KVCacheBlock
  KVCacheCoordinator o-- KVCacheConfig
  KVCacheCoordinator ..> Request
}

package "vllm.v1.core.kv_cache_utils" as utils {
  class "<<module>> kv_cache_utils" as kv_cache_utils {
    +get_kv_cache_groups(vllm_config, kv_cache_spec_per_layer): list[KVCacheGroupSpec]
    +unify_kv_cache_spec_page_size(...)
    +unify_hybrid_kv_cache_specs(...)  ..(disable_hybrid_kv_cache_manager 时把 spec 统一成单一类型)..
  }
}

package "vllm.distributed.kv_transfer.kv_connector" as conn {
  class KVConnectorFactory {
    +create_connector(config, role, kv_cache_config=None): KVConnectorBase
    ..(HMA enabled 时要求 connector supports_hma)..
  }

  class KVConnectorBase <<abstract>>
  class SupportsHMA <<marker/interface>>
  class "<<function>> supports_hma(connector_cls)" as supports_hma

  KVConnectorFactory ..> supports_hma
  KVConnectorFactory ..> KVCacheConfig
  KVConnectorFactory ..> KVConnectorBase
  SupportsHMA <|.. KVConnectorBase
}

utils.kv_cache_utils ..> core.KVCacheGroupSpec
utils.kv_cache_utils ..> core.KVCacheSpec
core.KVCacheCoordinator ..> core.SingleTypeKVCacheManager : get_manager_for_kv_cache_spec(...)
core.KVCacheManager ..> core.KVCacheCoordinator : uses

@enduml